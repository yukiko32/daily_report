## 取り組んだ課題一覧
- 米国AI開発者がゼロから教えるDocker講座  Udemy
	
## わかったこと
- Doker buildを実行すると、指定されたディレクトリとその中身のDockerfileがDocker daemonに渡され、imageを作成する。
- このディレクトリのことを`build context`という。ビルドに使わないファイルは`build context`の中に入れない。
- `COPY <src> <dest>`：Dockerfileに記述することで、`build context`に含めたファイルをimageに含めることができる。
- `FROM ubuntu:latest` + `RUN mkdir/new_dir` + `COPY something /new_dir/`：Dockerfileに記述することで、ルート直下にnew_dirディレクトリを作成＆Dockerfile内のsomethingファイルを作成したnew_dirディレクトリ内にコピーする
- `ADD <src> <dest>`：tarの圧縮ファイルをコピーして解凍したいときはADDを使用する。
- `docker build -f <dockerfilename（またはファイルのパス）> <buid context>`：「Dockerfile」という名前のファイルが`build context`に入っていない場合はこのように記述する。複数のdockerfileを使用する時など。開発系は`.dev`、テスト用は`.test`を末尾につけることが多い。このコマンドを使用すると、`build context`の外側のファイルを指定することもできる。
- `ENTRYPOINT ["command"]`：`CMD`と同様にデフォルトのコマンドを指定することができるが、`ENTRYPOINT`は`dpcker run`時に上書きすることができない。`ENTRYPOINT`を記述すると、`CMD`の記述は`CMD ["オプション"]`の形とする。（`ENTRYPOINT`のコマンドの引数）`dpcker run`時に上書きできるのは`CMD`の部分のみとなる。コンテナをコマンドのようにしたいときに使用する。
- `ENV <key>=<value>`：環境変数を設定する。runでコンテナ作成後、`env`コマンドで環境変数の一覧を確認できる。
- `WORKDIR <ディレクトリのパスを指定（なるべく絶対パス）>`：記述した行より下のDocker instructionの実行ディレクトリを変更する。Dockerfileに記述した`RUN`などの実行は全てルートディレクトリ直下で行われる。それを任意のディレクトリに変更するコマンド。（ディレクトリをmkdirで作っておかなくても、実行時に自動で作られる）

<br>

- ホストとコンテナの関係を理解する
- `-v <host（マウント元のパス）>:<container>`：`docker run`のオプションとして使用する。ホストのファイルシステムをコンテナにマウントする。そうすることでコンテナからホストのファイルシステムにアクセスできる。コンテナはなるべく軽くしておきたいため、コンテナは環境構築のみとすることがよくある。
- マウントするとコンテナの中にホストの中身が表示されるが、実体はホストにあり参照しているだけ。
- `-u <user id>:<group id>`：オプションにユーザIDとグループIDを指定して`docker run`する。（ubuntuは常にrootユーザになるため、rootユーザのままホストにアクセスできると問題が発生するため。）
- ターミナルで`id -u`とするとユーザID、`id -g`とするとグループIDを確認できる。`$(id -u):$(id -g)`とすることで、ターミナルでの出力結果を埋め込むことができる。
- ユーザIDをコンテナに渡してもユーザ名は渡されないので、ターミナルの表示名は`I have no name!`となる。
- `-p <host_port>:<container_port>`：ホストのポートをコンテナのポートに繋げる
- ターミナルでのCPU・メモリの確認コマンド
    - `sysctl -n hw.physicalcpu_max`：物理コア数
    - `sysctl -n hw.logicalcpu_max`：論理コア数
    - `sysctl hw.memsize`：メモリ（byte）
- `--cpus <# of CPUs>`：コンテナがアクセスできる上限のCPUを設定
- `--memory <byte>`：コンテナがアクセスできる上限のメモリを設定
- `docker inspect <containerID>`：コンテナの情報を見る。メモリの情報を見られる。
- `docker inspect <containerID> | grep -i cpu`；`cpu`が含まれるものを抜き出す（-iは大文字小文字問わない）`NanoCpus`の部分が使用可能なCPU。（10マイナス9乗の表示）
- `docker inspect <containerID> | grep -i memory`；`memory`が含まれるものを抜き出す。`Memory`の部分が使用可能なメモリ。

<br>

<h3>応用編1</h3>

- jupyter labとはPythonでデータ解析するツール。shift+enterキーでコードを実行できる。データサイエンスには欠かせないツールとなっている。
- ANACONDAはPythonのパッケージのこと。 jupyterも入っている。
- コンテナに環境構築をすることでホストに影響がなくなる。エラーが出たりコンフリクトが起きたらアンインストールの手間なく捨てられる。imageを他の人に渡せば、全く同じ環境を構築することができる。ホストが違うことでエラーが出たり出なかったりするが、コンテナではあり得ない。
- Dockerfile作成の手順は、まずコンテナでコマンドを打って実行してみて、うまくいったらDockerfileに記述していく。
- パスを通すとは、環境変数$PATHにパスを追加することで、コンピュータがそのパスからプログラムを探してくれるようになること。
- `echo $PATH`：今どこにパスが通っているか確認する
- `export PATH=/path/to/something:$PATH`でパスを追加する。（パスは`:`で繋ぐ。）`$PATH`には現在のパスが格納されているので、ここに新しいパスを追加してPATHに代入するイメージ。（先頭に書いてあるほうから優先される）
- パスを通すところは大抵`bin`となっている。
- `sh -x Anaconda3-2024.10-1-Linux-aarch64.sh `：`sh`ファイルが実行するオプションを確認できる。



## 次やること
米国AI開発者がゼロから教えるDocker講座  Udemy
	
## 感じたこと
基本コマンドの学習が一通り終了し、応用編ではコンテナでANACONDAを使用してjupyterlabをWebサーバで立ち上げました。
Dockerを実際にどのように使っていくのか、少しイメージすることができました。


## 学習時間
今日:7.5h
今週:33.5h 
累計:355.5h